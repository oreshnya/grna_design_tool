{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55fd03f5",
   "metadata": {},
   "source": [
    "### Imports & settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f371f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import io\n",
    "import os\n",
    "from contextlib import redirect_stdout, redirect_stderr\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio.Seq import Seq\n",
    "from Bio import SeqIO\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects import pandas2ri\n",
    "\n",
    "from rpy2.robjects.packages import importr\n",
    "import rpy2.rinterface_lib.callbacks\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f88f09ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\polina\\CRISPR\\grna_design_tool\\venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1788de56",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66ba7de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils = importr(\"utils\") \n",
    "# utils.install_packages(\"gbm\") # установка пакета R\n",
    "\n",
    "os.environ['RPY2_CCHAR_ENCODING'] = 'latin1'\n",
    "pandas2ri.activate()\n",
    "rpy2.rinterface_lib.callbacks.logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc5ba5a",
   "metadata": {},
   "source": [
    "### Функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86739676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sequence(userseq: str) -> str:\n",
    "    \"\"\"Load sequence from FASTA, TXT, or direct string\"\"\"\n",
    "    if userseq.endswith(\".fasta\") or userseq.endswith(\".fa\"):\n",
    "        records = list(SeqIO.parse(userseq, \"fasta\"))\n",
    "        sequence = str(records[0].seq)\n",
    "    elif userseq.endswith(\".txt\"):\n",
    "        with open(userseq, \"r\") as f:\n",
    "            sequence = \"\".join(line.strip() for line in f.readlines())\n",
    "    else:\n",
    "        sequence = userseq.replace(\" \", \"\").upper()\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43fa82a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_candidate_sgRNAs(sequence: str, pam: str = \"NGG\") -> list[dict]:\n",
    "    \"\"\"Find candidate sgRNAs with PAM motif in both strands\"\"\"\n",
    "    pam_regex = pam.replace(\"N\", \".\")\n",
    "    results = []\n",
    "\n",
    "    pam_pattern = re.compile(pam_regex)\n",
    "\n",
    "    for strand, seq in [('+', sequence), ('-', str(Seq(sequence).reverse_complement()))]:\n",
    "        for i in range(len(seq) - 29):\n",
    "            window = seq[i:i+30]\n",
    "            pam_candidate = window[24:24 + len(pam)]\n",
    "            if pam_pattern.fullmatch(pam_candidate):\n",
    "                sgRNA = window[4:24]\n",
    "                results.append({\n",
    "                    \"strand\": strand,\n",
    "                    \"start\": i+4 if strand == \"+\" else len(seq) - i - 26,\n",
    "                    \"end\": i+24 if strand == \"+\" else len(seq) - i - 6,\n",
    "                    \"sgRNA\": sgRNA,\n",
    "                    \"pam\": pam_candidate,\n",
    "                    \"window\": window\n",
    "                })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48673dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEGENERATE_BASES = re.compile(r\"[UWSMKRYBDHVNZ]\")  # некорректные символы\n",
    "HOMOPOLYMER_PATTERN = re.compile(r\"(A{4,}|T{4,}|G{4,}|C{4,})\")\n",
    "\n",
    "def is_valid(seq: str) -> bool:\n",
    "    return not DEGENERATE_BASES.search(seq)\n",
    "\n",
    "def get_gc_content(seq: str) -> float:\n",
    "    return (seq.count(\"G\") + seq.count(\"C\")) / len(seq)\n",
    "\n",
    "def has_homopolymer(seq: str) -> bool:\n",
    "    return bool(HOMOPOLYMER_PATTERN.search(seq))\n",
    "\n",
    "BACKBONE = Seq(\"AGGCTAGTCCGT\")\n",
    "REVCOMP_BACKBONE = BACKBONE.reverse_complement()\n",
    "\n",
    "def gc_content_4bp(seq4: str) -> float:\n",
    "    return (seq4.count(\"G\") + seq4.count(\"C\")) / 4\n",
    "\n",
    "def count_self_complementarity(sgRNA: str) -> int:\n",
    "    sg_seq = Seq(sgRNA)\n",
    "    revcomp_sg = sg_seq.reverse_complement()\n",
    "    score = 0\n",
    "\n",
    "    for i in range(0, len(sgRNA) - 3):  # 4-меры от 0 до 16\n",
    "        tetramer = sgRNA[i:i+4]\n",
    "        if gc_content_4bp(tetramer) >= 0.5:\n",
    "            # Сравниваем с обратным комплементом самого sgRNA\n",
    "            search_region = sgRNA[i+7:] if i <= 10 else \"\"\n",
    "            if tetramer in Seq(search_region).reverse_complement():\n",
    "                score += 1\n",
    "            # Сравниваем с обратным комплементом бекбона\n",
    "            if tetramer in REVCOMP_BACKBONE:\n",
    "                score += 1\n",
    "    return score\n",
    "\n",
    "def filter_sgRNAs(candidates: list[dict]) -> list[dict]:\n",
    "    filtered = []\n",
    "    for c in candidates:\n",
    "        if not is_valid(c[\"window\"]):\n",
    "            continue\n",
    "        sgRNA_seq = c[\"sgRNA\"]\n",
    "        pam_seq = c[\"pam\"]\n",
    "        gc_content = get_gc_content(sgRNA_seq)\n",
    "        homopolymer = has_homopolymer(sgRNA_seq)\n",
    "        self_comp_score = count_self_complementarity(sgRNA_seq)\n",
    "\n",
    "        filtered.append({\n",
    "            **c,\n",
    "            \"sgRNA_seq\": sgRNA_seq,\n",
    "            \"pam_seq\": pam_seq,\n",
    "            \"gc_content\": round(gc_content, 3),\n",
    "            \"homopolymer\": homopolymer,\n",
    "            \"self_complementarity\": self_comp_score\n",
    "        })\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56b1065a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict_from_r_model(df_features):\n",
    "#     robjects.r('library(gbm)')\n",
    "#     r_df = pandas2ri.py2rpy(df_features)\n",
    "#     # передаём всю команду как строку, включая параметры\n",
    "#     robjects.globalenv[\"df_features_r\"] = r_df\n",
    "#     pred = robjects.r('predict(model, df_features_r, n.trees=500)')\n",
    "#     return list(pred)\n",
    "\n",
    "def predict_from_r_model(df_features):\n",
    "    gbm = importr(\"gbm\")  # безопасный импорт пакета, не вызывает строковый вывод\n",
    "    r_df = pandas2ri.py2rpy(df_features)\n",
    "    robjects.globalenv[\"df_features_r\"] = r_df\n",
    "\n",
    "    with redirect_stdout(io.StringIO()), redirect_stderr(io.StringIO()):\n",
    "        pred = robjects.r('predict(model, df_features_r, n.trees=500)')\n",
    "    \n",
    "    return list(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97f83a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataframe(sgrna_candidates, features_df, efficiency_scores):\n",
    "    \"\"\"\n",
    "    Сборка итогового датафрейма:\n",
    "    - sgrna_candidates: список словарей с полями sgRNA, pam, strand, start, end, window\n",
    "    - features_df: датафрейм признаков (выход Doench_2016_processing)\n",
    "    - efficiency_scores: список float значений от модели\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.DataFrame(sgrna_candidates)\n",
    "    df[\"efficiency_score\"] = [round(x, 3) for x in efficiency_scores]\n",
    "\n",
    "    # Подсчёт GC-содержания 20-mer sgRNA\n",
    "    df[\"GC_content\"] = df[\"sgRNA\"].apply(lambda x: round((x.count(\"G\") + x.count(\"C\")) / len(x), 3))\n",
    "\n",
    "    # Детектирование гомополимеров\n",
    "    df[\"Homopolymer\"] = df[\"sgRNA\"].apply(lambda x: any(rep in x for rep in [\"AAAA\", \"TTTT\", \"GGGG\", \"CCCC\"]))\n",
    "\n",
    "    # Простейшая проверка самокомплементарности (временно — длина обратной комплементарной пары > 0)\n",
    "    df[\"Self_complementary\"] = df[\"sgRNA\"].apply(lambda x: \"CG\" in x[::-1] or \"GC\" in x[::-1])  # упрощённо\n",
    "\n",
    "    # Генерация Notes\n",
    "    def generate_notes(row):\n",
    "        notes = []\n",
    "        if row[\"GC_content\"] < 0.3:\n",
    "            notes.append(\"Low GC\")\n",
    "        elif row[\"GC_content\"] > 0.8:\n",
    "            notes.append(\"High GC\")\n",
    "        if row[\"Homopolymer\"]:\n",
    "            notes.append(\"Homopolymer\")\n",
    "        if row[\"Self_complementary\"]:\n",
    "            notes.append(\"Self Complementary\")\n",
    "        if row[\"efficiency_score\"] < 0.5:\n",
    "            notes.append(\"Low Efficiency\")\n",
    "        if not notes:\n",
    "            return \"N/A\"\n",
    "        return \", \".join(notes)\n",
    "\n",
    "    df[\"Notes\"] = df.apply(generate_notes, axis=1)\n",
    "\n",
    "    df = df.sort_values(by=\"efficiency_score\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # import ace_tools as tools; tools.display_dataframe_to_user(name=\"sgRNA Candidates\", dataframe=df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17f5652",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef1b5e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "robjects.r('model <- readRDS(\"models/Doench_2016/Rule_set_2_Model.rds\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "759a6c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "robjects.r('source(\"R/Doench_2016_processing.R\")')\n",
    "\n",
    "def generate_features_in_r(sgrna_windows: list[str]):\n",
    "    sgrna_vector = robjects.StrVector(sgrna_windows)\n",
    "    with redirect_stdout(io.StringIO()):  # скрываем печать R в stdout\n",
    "        r_df = robjects.r['Doench_2016_processing'](sgrna_vector)\n",
    "    return pandas2ri.rpy2py(r_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73e1e534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найдено 170 sgRNA-кандидатов.\n",
      "[{'strand': '+', 'start': 30, 'end': 50, 'sgRNA': 'CCAGTCAATTCAAGTCTCAA', 'pam': 'AGG', 'window': 'AGATCCAGTCAATTCAAGTCTCAAAGGGTT'}, {'strand': '+', 'start': 31, 'end': 51, 'sgRNA': 'CAGTCAATTCAAGTCTCAAA', 'pam': 'GGG', 'window': 'GATCCAGTCAATTCAAGTCTCAAAGGGTTT'}, {'strand': '+', 'start': 62, 'end': 82, 'sgRNA': 'TGCTAACCCCTCCATTACGC', 'pam': 'TGG', 'window': 'CCCTTGCTAACCCCTCCATTACGCTGGTCC'}]\n",
      "Осталось 170 sgRNA после фильтрации.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strand</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>sgRNA</th>\n",
       "      <th>pam</th>\n",
       "      <th>window</th>\n",
       "      <th>sgRNA_seq</th>\n",
       "      <th>pam_seq</th>\n",
       "      <th>gc_content</th>\n",
       "      <th>homopolymer</th>\n",
       "      <th>self_complementarity</th>\n",
       "      <th>efficiency_score</th>\n",
       "      <th>GC_content</th>\n",
       "      <th>Homopolymer</th>\n",
       "      <th>Self_complementary</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-</td>\n",
       "      <td>378</td>\n",
       "      <td>398</td>\n",
       "      <td>CATCACCTATGACAGCAACG</td>\n",
       "      <td>CGG</td>\n",
       "      <td>ACATCATCACCTATGACAGCAACGCGGCAG</td>\n",
       "      <td>CATCACCTATGACAGCAACG</td>\n",
       "      <td>CGG</td>\n",
       "      <td>0.50</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.50</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Self Complementary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>+</td>\n",
       "      <td>405</td>\n",
       "      <td>425</td>\n",
       "      <td>GCAGTTGGCAGAGAAAAGGG</td>\n",
       "      <td>TGG</td>\n",
       "      <td>TGTTGCAGTTGGCAGAGAAAAGGGTGGTAT</td>\n",
       "      <td>GCAGTTGGCAGAGAAAAGGG</td>\n",
       "      <td>TGG</td>\n",
       "      <td>0.55</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.55</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Homopolymer, Self Complementary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>+</td>\n",
       "      <td>156</td>\n",
       "      <td>176</td>\n",
       "      <td>GGACATGAACCTACACACGC</td>\n",
       "      <td>CGG</td>\n",
       "      <td>TAGTGGACATGAACCTACACACGCCGGTTT</td>\n",
       "      <td>GGACATGAACCTACACACGC</td>\n",
       "      <td>CGG</td>\n",
       "      <td>0.55</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.55</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Self Complementary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>+</td>\n",
       "      <td>1310</td>\n",
       "      <td>1330</td>\n",
       "      <td>GAAGGACTCATTATCTCAGG</td>\n",
       "      <td>CGG</td>\n",
       "      <td>TGTCGAAGGACTCATTATCTCAGGCGGTTG</td>\n",
       "      <td>GAAGGACTCATTATCTCAGG</td>\n",
       "      <td>CGG</td>\n",
       "      <td>0.45</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.45</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>+</td>\n",
       "      <td>875</td>\n",
       "      <td>895</td>\n",
       "      <td>GGAAAATTACAACATAACCC</td>\n",
       "      <td>CGG</td>\n",
       "      <td>TAAAGGAAAATTACAACATAACCCCGGTTC</td>\n",
       "      <td>GGAAAATTACAACATAACCC</td>\n",
       "      <td>CGG</td>\n",
       "      <td>0.35</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.35</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Homopolymer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  strand  start   end                 sgRNA  pam  \\\n",
       "0      -    378   398  CATCACCTATGACAGCAACG  CGG   \n",
       "1      +    405   425  GCAGTTGGCAGAGAAAAGGG  TGG   \n",
       "2      +    156   176  GGACATGAACCTACACACGC  CGG   \n",
       "3      +   1310  1330  GAAGGACTCATTATCTCAGG  CGG   \n",
       "4      +    875   895  GGAAAATTACAACATAACCC  CGG   \n",
       "\n",
       "                           window             sgRNA_seq pam_seq  gc_content  \\\n",
       "0  ACATCATCACCTATGACAGCAACGCGGCAG  CATCACCTATGACAGCAACG     CGG        0.50   \n",
       "1  TGTTGCAGTTGGCAGAGAAAAGGGTGGTAT  GCAGTTGGCAGAGAAAAGGG     TGG        0.55   \n",
       "2  TAGTGGACATGAACCTACACACGCCGGTTT  GGACATGAACCTACACACGC     CGG        0.55   \n",
       "3  TGTCGAAGGACTCATTATCTCAGGCGGTTG  GAAGGACTCATTATCTCAGG     CGG        0.45   \n",
       "4  TAAAGGAAAATTACAACATAACCCCGGTTC  GGAAAATTACAACATAACCC     CGG        0.35   \n",
       "\n",
       "   homopolymer  self_complementarity  efficiency_score  GC_content  \\\n",
       "0        False                     0             0.786        0.50   \n",
       "1         True                     0             0.741        0.55   \n",
       "2        False                     1             0.711        0.55   \n",
       "3        False                     2             0.700        0.45   \n",
       "4         True                     0             0.695        0.35   \n",
       "\n",
       "   Homopolymer  Self_complementary                            Notes  \n",
       "0        False                True               Self Complementary  \n",
       "1         True                True  Homopolymer, Self Complementary  \n",
       "2        False                True               Self Complementary  \n",
       "3        False               False                              N/A  \n",
       "4         True               False                      Homopolymer  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = load_sequence(\"data/DAK1.fasta\")\n",
    "candidates = find_candidate_sgRNAs(sequence, pam=\"NGG\")\n",
    "print(f\"Найдено {len(candidates)} sgRNA-кандидатов.\")\n",
    "print(candidates[:3])\n",
    "\n",
    "filtered = filter_sgRNAs(candidates)\n",
    "print(f\"Осталось {len(filtered)} sgRNA после фильтрации.\")\n",
    "\n",
    "windows = [x[\"window\"] for x in filtered]\n",
    "features_df = generate_features_in_r(windows)\n",
    "\n",
    "scores = predict_from_r_model(features_df)\n",
    "df_sg_candidates  = build_dataframe(filtered, features_df, scores)\n",
    "df_sg_candidates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "783844fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_sg_candidates.sgRNA_seq.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061b193f",
   "metadata": {},
   "source": [
    "### CRIPSR-BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e89246e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from models.CRISPR_BERT.model import build_bert\n",
    "from models.CRISPR_BERT.Encoder_change import BERT_encode, C_RNN_encode\n",
    "from models.CRISPR_BERT.Encoder_change import Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23ffa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_to_df(path, n_rows=1000):\n",
    "    \"\"\"Загружает sgRNA/off_target/label из CSV\"\"\"\n",
    "    df = pd.read_csv(path, names=[\"sgRNA\", \"off_target\", \"label\"], nrows=n_rows)\n",
    "    df[\"label\"] = df[\"label\"].astype(int)\n",
    "    return df\n",
    "\n",
    "def prepare_crisprbert_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Подготавливает датафрейм для подачи в CRISPR-BERT:\n",
    "    - совмещает sgRNA и off_target по позициям (одинаковой длины);\n",
    "    - приводит пары нуклеотидов к нижнему регистру;\n",
    "    - заменяет '_' на 'x';\n",
    "    - соединяет в строку, разделённую запятой.\n",
    "    \"\"\"\n",
    "    paired_sequences = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        sgrna = row[\"sgRNA\"].replace(\"_\", \"X\").lower()\n",
    "        off = row[\"off_target\"].replace(\"_\", \"X\").lower()\n",
    "\n",
    "        if len(sgrna) != len(off):\n",
    "            print(f\"⚠️ Строка #{idx}: длины sgRNA и off_target не совпадают → пропущена\")\n",
    "            paired_sequences.append(\"\")  # или можно вставить заглушку 'xx,xx,...'\n",
    "            continue\n",
    "\n",
    "        pairs = [sgrna[i] + off[i] for i in range(len(sgrna))]\n",
    "        sequence_str = \",\".join(pairs)\n",
    "        paired_sequences.append(sequence_str)\n",
    "\n",
    "    df = df.copy()\n",
    "    df[\"sequence\"] = paired_sequences\n",
    "    return df[[\"sequence\", \"label\", \"sgRNA\", \"off_target\"]]\n",
    "\n",
    "\n",
    "def predict_crisprbert_from_df(df: pd.DataFrame, model_weights_path: str, n_predict=100):\n",
    "    \"\"\"Кодирует и предсказывает off-target вероятность\"\"\"\n",
    "    df_subset = df.iloc[:n_predict].copy()\n",
    "    \n",
    "    # BERT inputs\n",
    "    data_list = df_subset[[\"sequence\", \"label\"]].values.tolist()\n",
    "    token_ids, segment_ids = BERT_encode(data_list)\n",
    "\n",
    "    # RNN inputs\n",
    "    rnn_encoded = np.array(C_RNN_encode(df_subset))\n",
    "\n",
    "    # Модель\n",
    "    model = build_bert()\n",
    "    model.load_weights(model_weights_path)\n",
    "\n",
    "    # Предсказания\n",
    "    y_pred = model.predict([rnn_encoded, np.array(token_ids), np.array(segment_ids)])\n",
    "    return df_subset, y_pred\n",
    "\n",
    "\n",
    "def encode_sequence_column(df: pd.DataFrame, column: str = \"sequence\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Применяет Encoder к колонке с биграммами (в виде строки через запятую),\n",
    "    добавляет закодированные данные в столбец 'rnn_encoded'.\n",
    "    \"\"\"\n",
    "    encoded_list = []\n",
    "    for i, val in enumerate(df[column]):\n",
    "        try:\n",
    "            merged = val.replace(\",\", \"\")  # склеиваем биграммы в строку длины 52\n",
    "            en = Encoder(merged)\n",
    "            encoded_list.append(en.on_off_code)\n",
    "        except KeyError as e:\n",
    "            print(f\"⚠️ Ошибка кодирования в строке {i}: {e} → {val}\")\n",
    "            encoded_list.append(np.zeros((26, 7), dtype=int))  # fallback для некорректных строк\n",
    "\n",
    "    df[\"rnn_encoded\"] = encoded_list\n",
    "    return df\n",
    "\n",
    "\n",
    "def encode_with_bert_tokenizer(df: pd.DataFrame, column: str = \"sequence\"):\n",
    "    \"\"\"\n",
    "    Применяет BERT_encode к колонке с биграммами и добавляет token_ids и segment_ids в датафрейм.\n",
    "    \"\"\"\n",
    "    data_for_encoding = []\n",
    "    for val in df[column]:\n",
    "        tokens = val.split(',')\n",
    "        tokens = [t.strip() for t in tokens if t]  # очистка\n",
    "        text = \" \".join(tokens)\n",
    "        data_for_encoding.append((text, 0))  # фиктивный label\n",
    "    \n",
    "    token_ids, segment_ids = BERT_encode(data_for_encoding)\n",
    "    df[\"bert_token_ids\"] = token_ids\n",
    "    df[\"bert_segment_ids\"] = segment_ids\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_rnn_encoded_column(df: pd.DataFrame, column: str = \"sequence\", n_nucl: int = 24) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Добавляет столбец rnn_encoded — результат работы Encoder (OHE-кодировка биграмм).\n",
    "    Если биграмм меньше 26, добавляется padding 'xx'.\n",
    "    \"\"\"\n",
    "    encoded = []\n",
    "    for i, val in enumerate(df[column]):\n",
    "        try:\n",
    "            bigrams = val.split(\",\")\n",
    "            # паддинг до 26 биграмм\n",
    "            if len(bigrams) < n_nucl:\n",
    "                bigrams += [\"xx\"] * (n_nucl - len(bigrams))\n",
    "            elif len(bigrams) > n_nucl:\n",
    "                bigrams = bigrams[:n_nucl]\n",
    "            # оборачиваем в строку без запятых\n",
    "            merged = \"\".join(bigrams)\n",
    "            en = Encoder(merged)\n",
    "            encoded.append(en.on_off_code)\n",
    "        except KeyError as e:\n",
    "            print(f\"⚠️ Ошибка кодирования RNN в строке {i}: {e} → {val}\")\n",
    "            encoded.append(np.zeros((n_nucl+2, 7)))  # с запасом\n",
    "    df = df.copy()\n",
    "    df[\"rnn_encoded\"] = encoded\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_bert_encoding_columns(df: pd.DataFrame, column: str = \"sequence\", n_nucl: int = 24) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Добавляет в DataFrame две колонки:\n",
    "    - bert_token_ids — токен-идентификаторы (из token_dict)\n",
    "    - bert_segment_ids — список нулей того же размера.\n",
    "    \n",
    "    При необходимости добавляет 'xx'-паддинг до n_nucl биграмм.\n",
    "    \"\"\"\n",
    "    data_for_encoding = []\n",
    "    \n",
    "    for i, val in enumerate(df[column]):\n",
    "        try:\n",
    "            bigrams = val.strip().split(\",\")\n",
    "            # паддинг\n",
    "            if len(bigrams) < n_nucl:\n",
    "                bigrams += [\"xx\"] * (n_nucl - len(bigrams))\n",
    "            elif len(bigrams) > n_nucl:\n",
    "                bigrams = bigrams[:n_nucl]\n",
    "\n",
    "            # преобразуем обратно в строку\n",
    "            padded_text = \",\".join(bigrams)\n",
    "            data_for_encoding.append((padded_text, 0))  # фиктивный label\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Ошибка при подготовке строки #{i} для BERT: {e}\")\n",
    "            data_for_encoding.append((\",\".join([\"xx\"] * n_nucl), 0))\n",
    "\n",
    "    token_ids, segment_ids = BERT_encode(data_for_encoding)\n",
    "\n",
    "    df = df.copy()\n",
    "    df[\"bert_token_ids\"] = token_ids\n",
    "    df[\"bert_segment_ids\"] = segment_ids\n",
    "    return df\n",
    "\n",
    "\n",
    "def run_crisprbert_prediction(df: pd.DataFrame, model, n_predict: int = 100) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Запускает CRISPR-BERT предсказания для первых n_predict строк датафрейма.\n",
    "    Предполагает наличие 'rnn_encoded', 'bert_token_ids', 'bert_segment_ids'.\n",
    "    Возвращает df с новой колонкой 'prediction' (вероятность off-target).\n",
    "    Остальные строки получают \"No pred\".\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Обрезаем подмножество\n",
    "    df_subset = df.iloc[:n_predict]\n",
    "    \n",
    "    # Собираем входы\n",
    "    rnn_encoded = np.array(df_subset[\"rnn_encoded\"].tolist())\n",
    "    token_ids = np.array(df_subset[\"bert_token_ids\"].tolist())\n",
    "    segment_ids = np.array(df_subset[\"bert_segment_ids\"].tolist())\n",
    "\n",
    "    # Предсказание\n",
    "    y_pred = model.predict([rnn_encoded, token_ids, segment_ids])\n",
    "\n",
    "    # Берём вероятность класса \"on-target = 1\" (index 1)\n",
    "    probs = [float(p[1]) for p in y_pred]\n",
    "\n",
    "    # Заполняем столбец предсказаний\n",
    "    df[\"prediction\"] = \"No pred\"\n",
    "    df.loc[:n_predict - 1, \"prediction\"] = probs\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab2fd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Настройки ===\n",
    "DATA_PATH = \"models/CRISPR_BERT/datasets/K562.txt\"\n",
    "\n",
    "# === Пайплайн ===\n",
    "df = load_data_to_df(DATA_PATH, n_rows=1000)\n",
    "df = prepare_crisprbert_df(df)\n",
    "df = add_rnn_encoded_column(df)\n",
    "df = add_bert_encoding_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "45ecf516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "      <th>sgRNA</th>\n",
       "      <th>off_target</th>\n",
       "      <th>rnn_encoded</th>\n",
       "      <th>bert_token_ids</th>\n",
       "      <th>bert_segment_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ag,ac,aa,tt,gg,aa,gg,aa,aa,gg,aa,aa,gg,aa,gg,g...</td>\n",
       "      <td>0</td>\n",
       "      <td>AAATGAGAAGAAGAGGCACAGGG</td>\n",
       "      <td>GCATGAGAAGAAGAGACATAGCC</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [1, 0, 1, 0, 0, 1, 0],...</td>\n",
       "      <td>[0, 4, 3, 2, 17, 12, 2, 12, 2, 2, 12, 2, 2, 12...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ag,aa,aa,tg,ga,aa,gg,aa,aa,gg,aa,aa,gg,aa,gg,g...</td>\n",
       "      <td>0</td>\n",
       "      <td>AAATGAGAAGAAGAGGCACAGGG</td>\n",
       "      <td>GAAGAAGAAGAAGAGGAAGAGGA</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [1, 0, 1, 0, 0, 1, 0],...</td>\n",
       "      <td>[0, 4, 2, 2, 16, 10, 2, 12, 2, 2, 12, 2, 2, 12...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt,gg,at,cc,aa,tt,cc,aa,aa,tt,tt,aa,tt,tt,aa,t...</td>\n",
       "      <td>0</td>\n",
       "      <td>TGACATCAATTATTATACATCGG</td>\n",
       "      <td>TGTCATCAATTATTAGGATTCGT</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0],...</td>\n",
       "      <td>[0, 17, 12, 5, 7, 2, 17, 7, 2, 2, 17, 17, 2, 1...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gt,aa,cc,aa,cc,cc,ga,aa,aa,gg,cc,aa,gg,aa,gg,t...</td>\n",
       "      <td>0</td>\n",
       "      <td>GACACCGAAGCAGAGTTTTTAGG</td>\n",
       "      <td>TACACCAAAGCAGAGTTTGGAGA</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [0, 1, 1, 0, 0, 0, 1],...</td>\n",
       "      <td>[0, 13, 2, 7, 2, 7, 7, 10, 2, 2, 12, 7, 2, 12,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ag,aa,aa,tg,ga,aa,gg,aa,ag,gg,aa,aa,gg,aa,gg,g...</td>\n",
       "      <td>0</td>\n",
       "      <td>AAATGAGAAGAAGAGGCACAGGG</td>\n",
       "      <td>GAAGAAGAGGAAGAGACACAAGG</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0], [1, 0, 1, 0, 0, 1, 0],...</td>\n",
       "      <td>[0, 4, 2, 2, 16, 10, 2, 12, 2, 4, 12, 2, 2, 12...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sequence  label  \\\n",
       "0  ag,ac,aa,tt,gg,aa,gg,aa,aa,gg,aa,aa,gg,aa,gg,g...      0   \n",
       "1  ag,aa,aa,tg,ga,aa,gg,aa,aa,gg,aa,aa,gg,aa,gg,g...      0   \n",
       "2  tt,gg,at,cc,aa,tt,cc,aa,aa,tt,tt,aa,tt,tt,aa,t...      0   \n",
       "3  gt,aa,cc,aa,cc,cc,ga,aa,aa,gg,cc,aa,gg,aa,gg,t...      0   \n",
       "4  ag,aa,aa,tg,ga,aa,gg,aa,ag,gg,aa,aa,gg,aa,gg,g...      0   \n",
       "\n",
       "                     sgRNA               off_target  \\\n",
       "0  AAATGAGAAGAAGAGGCACAGGG  GCATGAGAAGAAGAGACATAGCC   \n",
       "1  AAATGAGAAGAAGAGGCACAGGG  GAAGAAGAAGAAGAGGAAGAGGA   \n",
       "2  TGACATCAATTATTATACATCGG  TGTCATCAATTATTAGGATTCGT   \n",
       "3  GACACCGAAGCAGAGTTTTTAGG  TACACCAAAGCAGAGTTTGGAGA   \n",
       "4  AAATGAGAAGAAGAGGCACAGGG  GAAGAAGAGGAAGAGACACAAGG   \n",
       "\n",
       "                                         rnn_encoded  \\\n",
       "0  [[0, 0, 0, 0, 0, 0, 0], [1, 0, 1, 0, 0, 1, 0],...   \n",
       "1  [[0, 0, 0, 0, 0, 0, 0], [1, 0, 1, 0, 0, 1, 0],...   \n",
       "2  [[0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0],...   \n",
       "3  [[0, 0, 0, 0, 0, 0, 0], [0, 1, 1, 0, 0, 0, 1],...   \n",
       "4  [[0, 0, 0, 0, 0, 0, 0], [1, 0, 1, 0, 0, 1, 0],...   \n",
       "\n",
       "                                      bert_token_ids  \\\n",
       "0  [0, 4, 3, 2, 17, 12, 2, 12, 2, 2, 12, 2, 2, 12...   \n",
       "1  [0, 4, 2, 2, 16, 10, 2, 12, 2, 2, 12, 2, 2, 12...   \n",
       "2  [0, 17, 12, 5, 7, 2, 17, 7, 2, 2, 17, 17, 2, 1...   \n",
       "3  [0, 13, 2, 7, 2, 7, 7, 10, 2, 2, 12, 7, 2, 12,...   \n",
       "4  [0, 4, 2, 2, 16, 10, 2, 12, 2, 4, 12, 2, 2, 12...   \n",
       "\n",
       "                                    bert_segment_ids  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cd422f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\polina\\CRISPR\\grna_design_tool\\venv\\Lib\\site-packages\\keras\\src\\initializers\\initializers.py:120: UserWarning: The initializer GlorotNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_22\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_19 (InputLayer)       [(None, 26, 7)]              0         []                            \n",
      "                                                                                                  \n",
      " reshape_12 (Reshape)        (None, 1, 26, 7)             0         ['input_19[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)          (None, 1, 26, 5)             40        ['reshape_12[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)          (None, 1, 26, 15)            435       ['reshape_12[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)          (None, 1, 26, 25)            1600      ['reshape_12[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)          (None, 1, 26, 35)            6160      ['reshape_12[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate  (None, 1, 26, 80)            0         ['conv2d_24[0][0]',           \n",
      " )                                                                   'conv2d_25[0][0]',           \n",
      "                                                                     'conv2d_26[0][0]',           \n",
      "                                                                     'conv2d_27[0][0]']           \n",
      "                                                                                                  \n",
      " input_20 (InputLayer)       [(None, 26)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_21 (InputLayer)       [(None, 26)]                 0         []                            \n",
      "                                                                                                  \n",
      " reshape_13 (Reshape)        (None, 26, 80)               0         ['concatenate_6[0][0]']       \n",
      "                                                                                                  \n",
      " model_21 (Functional)       (None, None, 256)            9525248   ['input_20[0][0]',            \n",
      "                                                                     'input_21[0][0]']            \n",
      "                                                                                                  \n",
      " bidirectional_12 (Bidirect  (None, 26, 80)               29280     ['reshape_13[0][0]']          \n",
      " ional)                                                                                           \n",
      "                                                                                                  \n",
      " bidirectional_13 (Bidirect  (None, 26, 80)               71520     ['model_21[0][0]']            \n",
      " ional)                                                                                           \n",
      "                                                                                                  \n",
      " lambda_19 (Lambda)          (None, 26, 80)               0         ['bidirectional_12[0][0]']    \n",
      "                                                                                                  \n",
      " lambda_20 (Lambda)          (None, 26, 80)               0         ['bidirectional_13[0][0]']    \n",
      "                                                                                                  \n",
      " lambda_18 (Lambda)          (None, 26, 160)              0         ['lambda_19[0][0]',           \n",
      "                                                                     'lambda_20[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_6 (Flatten)         (None, 4160)                 0         ['lambda_18[0][0]']           \n",
      "                                                                                                  \n",
      " dense_18 (Dense)            (None, 128)                  532608    ['flatten_6[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)        (None, 128)                  0         ['dense_18[0][0]']            \n",
      "                                                                                                  \n",
      " dense_19 (Dense)            (None, 64)                   8256      ['dropout_12[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)        (None, 64)                   0         ['dense_19[0][0]']            \n",
      "                                                                                                  \n",
      " dense_20 (Dense)            (None, 2)                    130       ['dropout_13[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 10175277 (38.82 MB)\n",
      "Trainable params: 10175277 (38.82 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "WEIGHTS_PATH = \"models/CRISPR_BERT/weight/I1.h5\"\n",
    "\n",
    "bert_model = build_bert()\n",
    "bert_model.load_weights(WEIGHTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3ccfd1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 4s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sgRNA</th>\n",
       "      <th>off_target</th>\n",
       "      <th>label</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAATGAGAAGAAGAGGCACAGGG</td>\n",
       "      <td>GCATGAGAAGAAGAGACATAGCC</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAATGAGAAGAAGAGGCACAGGG</td>\n",
       "      <td>GAAGAAGAAGAAGAGGAAGAGGA</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TGACATCAATTATTATACATCGG</td>\n",
       "      <td>TGTCATCAATTATTAGGATTCGT</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GACACCGAAGCAGAGTTTTTAGG</td>\n",
       "      <td>TACACCAAAGCAGAGTTTGGAGA</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAATGAGAAGAAGAGGCACAGGG</td>\n",
       "      <td>GAAGAAGAGGAAGAGACACAAGG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GGGTGGGGGGAGTTTGCTCCTGG</td>\n",
       "      <td>GATTTGGGGGAGTTTGCTCAGGC</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ATGAACACCAGTGAGTAGAGCGG</td>\n",
       "      <td>GTGGGCAACAGTGAGTAGAGCAG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GGTCCTGCCGCTGCTTGTCATGG</td>\n",
       "      <td>GGCTCAGCTGGGGCTTGTCATGG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AAATGAGAAGAAGAGGCACAGGG</td>\n",
       "      <td>AGATAGGAGGAAGAGGCATTGGG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CCTGCCTCCGCTCTACTCACTGG</td>\n",
       "      <td>CCTGCCTCCTCTTTACACATTCA</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     sgRNA               off_target  label prediction\n",
       "0  AAATGAGAAGAAGAGGCACAGGG  GCATGAGAAGAAGAGACATAGCC      0        0.0\n",
       "1  AAATGAGAAGAAGAGGCACAGGG  GAAGAAGAAGAAGAGGAAGAGGA      0        0.0\n",
       "2  TGACATCAATTATTATACATCGG  TGTCATCAATTATTAGGATTCGT      0        0.0\n",
       "3  GACACCGAAGCAGAGTTTTTAGG  TACACCAAAGCAGAGTTTGGAGA      0        0.0\n",
       "4  AAATGAGAAGAAGAGGCACAGGG  GAAGAAGAGGAAGAGACACAAGG      0        0.0\n",
       "5  GGGTGGGGGGAGTTTGCTCCTGG  GATTTGGGGGAGTTTGCTCAGGC      0        0.0\n",
       "6  ATGAACACCAGTGAGTAGAGCGG  GTGGGCAACAGTGAGTAGAGCAG      0   0.000057\n",
       "7  GGTCCTGCCGCTGCTTGTCATGG  GGCTCAGCTGGGGCTTGTCATGG      0        0.0\n",
       "8  AAATGAGAAGAAGAGGCACAGGG  AGATAGGAGGAAGAGGCATTGGG      0        0.0\n",
       "9  CCTGCCTCCGCTCTACTCACTGG  CCTGCCTCCTCTTTACACATTCA      0        0.0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_preds = run_crisprbert_prediction(df, bert_model, n_predict=100)\n",
    "df_with_preds[[\"sgRNA\", \"off_target\", \"label\", \"prediction\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad1eb25",
   "metadata": {},
   "source": [
    "### Relative activity predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81be68b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.RA_predictor.RA_predictor import build_relative_activity_predictor\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702c6335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv_1 (Conv2D)             (None, 7, 26, 32)         544       \n",
      "                                                                 \n",
      " dense_2 (Conv2D)            (None, 7, 26, 32)         16416     \n",
      "                                                                 \n",
      " dense_3 (MaxPooling2D)      (None, 7, 13, 32)         0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 7, 13, 32)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2912)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               745728    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " float_dense_5 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " float_dense_7 (Dense)       (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 795713 (3.04 MB)\n",
      "Trainable params: 795713 (3.04 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 1 variables whereas the saved optimizer has 21 variables. \n"
     ]
    }
   ],
   "source": [
    "WEIGHTS_PATH_RA = os.path.join(\"models\", \"RA_predictor\", \"RA_predictor_1.weights.h5\")\n",
    "\n",
    "ra_model = build_relative_activity_predictor()\n",
    "ra_model.load_weights(WEIGHTS_PATH_RA)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
